{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = '''A random shooting injured five people Saturday, including three members of a Joplin, Missouri, church who were starting a trip to St. Louis, police said.  A 26-year-old suspect was taken into custody and was being held but has not been formally charged, The Joplin Globe reported.  “This came out of the blue, and all of a sudden people were shot and going to the hospital,” said Jason Glaskey, director of Christian education at Immanuel Lutheran Church, where three of the injured people take part in the church’s Comfort Dog ministry. Glaskey said two dogs were in the van and injured, but that no one else in the van was injured.  Police Capt. Bob Higginbotham told AP Radio that there was no apparent motive for the shootings, which began after the suspect’s father called police to report the suspect was firing rounds at their home.  Officers went to the home, and then began pursuing a suspect vehicle. Police said the driver of that vehicle fired shots at the church van, which was stopped at a traffic light. Two people in the van were taken to a hospital, with one in critical condition and the other in serious but stable condition. One was released.  Also, two comfort dogs, which provide assistance to people, were injured, Glaskey told the newspaper. One was released, and one was still getting medical care Saturday afternoon.  Police said the suspect then shot at a pickup truck, injuring two adults. The driver is hospitalized, and the passenger was released, according to police.  “As rounds were being fired, they (police) continued to stay with that suspect, continued to pursue that suspect even though they knew the suspect was actively firing his weapon,” Police Chief Matt Stewart said at a news conference.  The man surrendered and was arrested at 5:22 a.m., police said.  “We are very grateful that these victims do not appear to have life-threatening wounds because of this act,” Mayor Mike Seibert said.  Glaskey said he did not think anyone at the church knew the suspect, adding: “It was random.”  Church member Vicki Eby was in the van with her husband, Kenneth, who was driving. She told KOAM-TV they heard “three pops go off.”  “It was so dark, we didn’t know what was happening,” she said.  One of the bullets hit her husband’s lung, she said, adding that he’s in critical condition.  “If they hadn’t of gotten him to the hospital when they did, he wouldn’t be here,” she said. “They said that his chances were very, very slim. I was in shock. I just asked if they were going to fix him.”  South Africa Today – World News – United States'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LemmaTokenizer(t):\n",
    "    \n",
    "    return (t.to_terms_list(\n",
    "                ngrams=1, named_entities=False, as_strings=True))\n",
    "    def process():\n",
    "        tokens = nlp(t)\n",
    "        for token in tokens:\n",
    "            if token.is_alpha:\n",
    "                yield token.lemma_ or token\n",
    "\n",
    "    return process()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', '', ''],\n",
       " ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['', '', '', '', '', '', ''],\n",
       " ['', ''],\n",
       " ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', ''],\n",
       " [''],\n",
       " ['', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', ''],\n",
       " ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['', '', '', ''],\n",
       " [''],\n",
       " ['', ''],\n",
       " ['', '', '', '', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', '', '', '', ''],\n",
       " ['', '', '', '', ''],\n",
       " ['', 'not', '', '', ''],\n",
       " ['', '', '', '', '', '', '', '', '', ''],\n",
       " ['not', '', '', 'not', ''],\n",
       " ['', '', ''],\n",
       " [''],\n",
       " ['', '', ''],\n",
       " ['', '', '', '', '', '', '']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = t.split('.')\n",
    "\n",
    "\n",
    "c = textacy.Corpus('en', texts=corpus)\n",
    "\n",
    "[list(LemmaTokenizer(doc)) for doc in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got Doc)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4e4848d84057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m      min_df=1, max_df=0.95)\n\u001b[1;32m      4\u001b[0m doc_term_matrix = vectorizer.fit_transform(\n\u001b[0;32m----> 5\u001b[0;31m      (LemmaTokenizer(doc) for doc in c))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/textacy/vsm.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, terms_list)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# count terms and build up a vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         doc_term_matrix, self.vocabulary = self._count_terms(\n\u001b[0;32m--> 211\u001b[0;31m             terms_list, self.is_fixed_vocabulary)\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# filter terms by doc freq or info content, as specified in init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/textacy/vsm.py\u001b[0m in \u001b[0;36m_count_terms\u001b[0;34m(self, terms_list, fixed_vocab)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mterm_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4e4848d84057>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m      min_df=1, max_df=0.95)\n\u001b[1;32m      4\u001b[0m doc_term_matrix = vectorizer.fit_transform(\n\u001b[0;32m----> 5\u001b[0;31m      (LemmaTokenizer(doc) for doc in c))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-0034fcae4efd>\u001b[0m in \u001b[0;36mLemmaTokenizer\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLemmaTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     print (nlp(t).to_terms_list(\n\u001b[0m\u001b[1;32m      4\u001b[0m                 ngrams=1, named_entities=True, as_strings=True))\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, tag, parse, entity)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'An'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \"\"\"\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;31m# Add any of the entity labels already set, in case we don't have them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_make_doc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'make_doc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'pipeline'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pipeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got Doc)"
     ]
    }
   ],
   "source": [
    "vectorizer = textacy.Vectorizer(\n",
    "     weighting='tfidf', normalize=True, smooth_idf=True,\n",
    "     min_df=1, max_df=0.95)\n",
    "doc_term_matrix = vectorizer.fit_transform(\n",
    "     (LemmaTokenizer(doc) for doc in c))\n",
    "vectorizer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_term_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1689b45abd82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_term_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "doc_term_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
